{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKCAHmIr3nQ1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1: Building the Core Architecture\n",
        "\n",
        "This notebook covers the main part of the project: implementing the custom Swin Transformer model. The first step is to define all the custom layers needed, like PatchEmbedding, WindowAttention, and the main SwinTransformer block itself. This is the foundation of the model."
      ],
      "metadata": {
        "id": "Hy7m2rRX3w6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "import os\n",
        "\n",
        "# --- Model Hyperparameters ---\n",
        "num_classes = 5\n",
        "input_shape = (224, 224, 3)\n",
        "patch_size = (4, 4)\n",
        "num_heads = 6\n",
        "embed_dim = 96\n",
        "num_mlp = 384\n",
        "qkv_bias = True\n",
        "window_size = 7\n",
        "shift_size = 3\n",
        "image_dimension = 224\n",
        "\n",
        "# --- Calculate patch details ---\n",
        "num_patch_x = input_shape[0] // patch_size[0]\n",
        "num_patch_y = input_shape[1] // patch_size[1]\n",
        "print(f\"Number of patches: {num_patch_x}x{num_patch_y} = {num_patch_x * num_patch_y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz0faHNZ3xUR",
        "outputId": "aef97790-71e1-4add-c5d4-ca1bc67a0a67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of patches: 56x56 = 3136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions\n",
        "\n",
        "These two functions are used to partition the image into windows and then reverse the proccess. This is a core idea of the Swin Transformer to compute attention locally."
      ],
      "metadata": {
        "id": "XCG0d0m-35-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = ops.reshape(\n",
        "        x, (-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
        "    )\n",
        "    x = ops.transpose(x, (0, 1, 3, 2, 4, 5))\n",
        "    windows = ops.reshape(x, (-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = ops.reshape(\n",
        "        windows, (-1, patch_num_y, patch_num_x, window_size, window_size, channels)\n",
        "    )\n",
        "    x = ops.transpose(x, (0, 1, 3, 2, 4, 5))\n",
        "    x = ops.reshape(x, (-1, height, width, channels))\n",
        "    return x"
      ],
      "metadata": {
        "id": "VfmdZXOy36Vm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Layers Implementation\n",
        "\n",
        "Now, I'm defining the main custom layers for the model.\n",
        "\n",
        "1.  **WindowAttention**: Computes self-attention within local windows.\n",
        "2.  **SwinTransformer**: The main block that combines window attention with the MLP.\n",
        "3.  **PatchEmbedding**: Converts image patches to vector embeddings.\n",
        "4.  **PatchMerging**: Downsamples the image by merging patches, which creates the hirearchical structure."
      ],
      "metadata": {
        "id": "FoXAtMZ33_DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "\n",
        "        # Define relative position bias\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1)\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=keras.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
        "        coords = np.stack(coords_matrix)\n",
        "        coords_flatten = coords.reshape(2, -1)\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = relative_coords.sum(-1)\n",
        "        self.relative_position_index = keras.Variable(\n",
        "            initializer=relative_position_index,\n",
        "            shape=relative_position_index.shape,\n",
        "            dtype=\"int\",\n",
        "            trainable=False,\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = ops.reshape(x_qkv, (-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = ops.transpose(x_qkv, (2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = ops.transpose(k, (0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = ops.reshape(self.relative_position_index, (-1,))\n",
        "        relative_position_bias = ops.take(self.relative_position_bias_table, relative_position_index_flat, axis=0)\n",
        "        relative_position_bias = ops.reshape(relative_position_bias, (num_window_elements, num_window_elements, -1))\n",
        "        relative_position_bias = ops.transpose(relative_position_bias, (2, 0, 1))\n",
        "        attn = attn + ops.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            mask_float = ops.cast(ops.expand_dims(ops.expand_dims(mask, axis=1), axis=0), \"float32\")\n",
        "            attn = ops.reshape(attn, (-1, nW, self.num_heads, size, size)) + mask_float\n",
        "            attn = ops.reshape(attn, (-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "\n",
        "        attn = self.dropout(attn)\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = ops.transpose(x_qkv, (0, 2, 1, 3))\n",
        "        x_qkv = ops.reshape(x_qkv, (-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv\n",
        "\n",
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(self, dim, num_patch, num_heads, window_size=7, shift_size=0, num_mlp=1024, qkv_bias=True, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.num_patch = num_patch\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.num_mlp = num_mlp\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = layers.Dropout(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.mlp = keras.Sequential([\n",
        "            layers.Dense(num_mlp),\n",
        "            layers.Activation(keras.activations.gelu),\n",
        "            layers.Dropout(dropout_rate),\n",
        "            layers.Dense(dim),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ])\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size > 0:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None))\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = ops.convert_to_tensor(mask_array)\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = ops.reshape(mask_windows, [-1, self.window_size * self.window_size])\n",
        "            attn_mask = ops.expand_dims(mask_windows, axis=1) - ops.expand_dims(mask_windows, axis=2)\n",
        "            attn_mask = ops.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = ops.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = keras.Variable(initializer=attn_mask, shape=attn_mask.shape, dtype=attn_mask.dtype, trainable=False)\n",
        "        else:\n",
        "            self.attn_mask = None\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        height, width = self.num_patch\n",
        "        _, num_patches_before, channels = x.shape\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = ops.reshape(x, (-1, height, width, channels))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = ops.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = ops.reshape(x_windows, (-1, self.window_size * self.window_size, channels))\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "        attn_windows = ops.reshape(attn_windows, (-1, self.window_size, self.window_size, channels))\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, height, width, channels)\n",
        "        if self.shift_size > 0:\n",
        "            x = ops.roll(shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = ops.reshape(x, (-1, height * width, channels))\n",
        "        x = self.drop_path(x, training=training)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        return x\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        pos = ops.arange(start=0, stop=self.num_patch)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "class PatchMerging(keras.layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.shape\n",
        "        x = ops.reshape(x, (-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = ops.concatenate((x0, x1, x2, x3), axis=-1)\n",
        "        x = ops.reshape(x, (-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)"
      ],
      "metadata": {
        "id": "y4ASxVmG39GD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Assembly\n",
        "\n",
        "Now I will assemble the layers together to build the final model. For this first attempt, I'll use a simple structure with two SwinTransformer blocks followed by a patch merging layer and a final classification head."
      ],
      "metadata": {
        "id": "Edt6rS4e4HKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Assembly ---\n",
        "patch_feature_dim = patch_size[0] * patch_size[1] * input_shape[2]\n",
        "num_patches_total = num_patch_x * num_patch_y\n",
        "input_layer_shape = (num_patches_total, patch_feature_dim)\n",
        "\n",
        "input_tensor = layers.Input(shape=input_layer_shape)\n",
        "\n",
        "# Stage 1\n",
        "x = PatchEmbedding(num_patches_total, embed_dim)(input_tensor)\n",
        "x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=0,\n",
        "    num_mlp=num_mlp,\n",
        "    name=\"swin_stage1_block1\"\n",
        ")(x)\n",
        "x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=shift_size,\n",
        "    num_mlp=num_mlp,\n",
        "    name=\"swin_stage1_block2\"\n",
        ")(x)\n",
        "\n",
        "# Downsampling\n",
        "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
        "\n",
        "# Final Classification Head\n",
        "x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the final model\n",
        "model = keras.Model(input_tensor, output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "GK78ksYh4HZG",
        "outputId": "2a46213f-0d09-4cbc-ed6d-27840e06a4c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_embedding                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │       \u001b[38;5;34m305,760\u001b[0m │\n",
              "│ (\u001b[38;5;33mPatchEmbedding\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_stage1_block1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │       \u001b[38;5;34m115,255\u001b[0m │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_stage1_block2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m, \u001b[38;5;34m96\u001b[0m)       │       \u001b[38;5;34m268,919\u001b[0m │\n",
              "│ (\u001b[38;5;33mSwinTransformer\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging (\u001b[38;5;33mPatchMerging\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │        \u001b[38;5;34m73,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m965\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_embedding                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">305,760</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEmbedding</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_stage1_block1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,255</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_stage1_block2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">268,919</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SwinTransformer</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchMerging</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m765,011\u001b[0m (3.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">765,011</span> (3.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m606,545\u001b[0m (2.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">606,545</span> (2.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m158,466\u001b[0m (1.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,466</span> (1.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}